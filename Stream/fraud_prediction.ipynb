{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711568e9-4943-40d6-aeee-93d8383a96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.runners.interactive import interactive_runner\n",
    "import apache_beam.runners.interactive.interactive_beam as ib\n",
    "from apache_beam.options import pipeline_options\n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
    "import google.auth\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4bbe1-c2ef-4ab7-a788-101152b3c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Apache Beam pipeline options.\n",
    "options = pipeline_options.PipelineOptions()\n",
    "\n",
    "# Sets the pipeline mode to streaming, so we can stream the data from PubSub.\n",
    "options.view_as(pipeline_options.StandardOptions).streaming = True\n",
    "\n",
    "# Sets the project to the default project in your current Google Cloud environment.\n",
    "# The project will be used for creating a subscription to the Pub/Sub topic.\n",
    "_, options.view_as(GoogleCloudOptions).project = google.auth.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df622d2-6831-4fe8-a84e-a71550836e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Google Cloud PubSub topic for this example.\n",
    "topic = \"projects/fraud-detection-data245/topics/payments_dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72487846-9dde-427e-92ad-0592c5175f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib.options.recording_duration = '20s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e186a-9238-4b1f-8e16-4a6406ec8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = beam.Pipeline(interactive_runner.InteractiveRunner(), options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809ba47-b89a-4ae7-bee2-74743478f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_transactions = p | \"read\" >> beam.io.ReadFromPubSub(topic=topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c112be-f3f5-45d9-bbb7-527bb8e1342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_payments = (payment_transactions \n",
    "                  | \"window\" >> beam.WindowInto(beam.window.FixedWindows(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8d38b-59bd-463a-9c65-8ab5a8c9f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib.show(windowed_payments, include_window_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358986a7-6c16-4e56-aeb9-7d322a23ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade faiss-cpu google-cloud-bigquery-storage google-cloud-storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68cd75c-9ec9-4a54-b9e1-ed9d36d3c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaissKNeighbors:\n",
    "    import numpy as np\n",
    "    import faiss\n",
    "    def __init__(self, k=5):\n",
    "        self.index = None\n",
    "        self.y = None\n",
    "        self.k = k\n",
    "    #IndexFlatL2 is Euclidean distance\n",
    "    def fit(self, X, y):\n",
    "        self.index = faiss.IndexFlatL2(X.shape[1])\n",
    "        self.index.add(X.astype(np.float32))\n",
    "        self.y = y\n",
    "    def predict(self, X):\n",
    "        distances, indices = self.index.search(X.astype(np.float32), k=self.k)\n",
    "        votes = self.y[indices]\n",
    "        predictions = np.array([np.argmax(np.bincount(x)) for x in votes])\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class ApplyDoFn(beam.DoFn):\n",
    "    def __init__(self):\n",
    "        #self._model = None\n",
    "        import pandas as pd\n",
    "        import pickle as pkl\n",
    "        import numpy as np\n",
    "        from google.cloud import bigquery\n",
    "        from google.cloud import storage\n",
    "        from apache_beam.io.gcp import gcsio\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        self._pkl = pkl\n",
    "        self._pd = pd\n",
    "        self.winningmodel = None\n",
    "        self.pickled_models = []\n",
    "        \n",
    "        client = bigquery.Client()\n",
    "        query_job = client.query(\n",
    "            \"\"\"\n",
    "            SELECT timestamp,modelName,confusionMatrix from `fraud-detection-data245.ml_project.metric` where timestamp>TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 4 DAY) order by modelName,foldNumber\"\"\"\n",
    "        )\n",
    "\n",
    "        #df = query_job.to_dataframe()\n",
    "        results = query_job.result()  \n",
    "        \n",
    "        model_results = []\n",
    "        for row in results:\n",
    "            model_results.append([row['timestamp'],row['modelName'],row['confusionMatrix']])\n",
    "       \n",
    "        #model_results \n",
    "        df = pd.DataFrame(model_results, columns=[\"timestamp\",\"modelName\",\"confusionMatrix\"])\n",
    "        \n",
    "        date = df['timestamp'].max().replace(hour = 0, minute = 0, second = 0)\n",
    "\n",
    "        df = df.loc[(df['timestamp'] >= date)]\n",
    "        \n",
    "        #F1 Score for all models\n",
    "        df['F1'] = df.apply(lambda row:(int(row['confusionMatrix']['truePositive']) / \n",
    "                                    (int(row['confusionMatrix']['truePositive']) + \n",
    "                                     (1/2 * (int(row['confusionMatrix']['falseNegative'] + row['confusionMatrix']['falsePositive']))))) ,  axis=1)\n",
    "        #print(df)\n",
    "        grouped_df = df.groupby(\"modelName\")\n",
    "        #print(grouped_df)\n",
    "        mean_df = grouped_df.mean()\n",
    "        mean_df = mean_df.reset_index()\n",
    "        print(\"F1 Scores for all Models Created:\")\n",
    "        print(mean_df)\n",
    "        min_recall = mean_df['F1'].min()\n",
    "        #print(min_recall)\n",
    "        mean_df = mean_df.loc[mean_df['F1'] > min_recall]\n",
    "        #mean_df = mean_df.loc[mean_df['F1'] > 0]\n",
    "        \n",
    "        print(\" \")\n",
    "        print(\"List of Model Considered after F1 Evaluation:\")\n",
    "        print(mean_df)\n",
    "        \n",
    "        models_considered = []\n",
    "        for i in range(len(mean_df.modelName)):\n",
    "            models_considered.append(mean_df['modelName'].iloc[i-1])\n",
    "        \n",
    "        print(models_considered)\n",
    "    \n",
    "        datepart = str(date)[0:10].replace(\"-\",\"\")\n",
    "        self.modelDirectory = datepart[6:8]+datepart[4:6]+datepart[0:4]\n",
    "        #print(self.modelDirectory)\n",
    "        storage_client = storage.Client()\n",
    "        gcs = gcsio.GcsIO()\n",
    "        \n",
    "        #Identifying the Directory for Model's Pickle Directroy\n",
    "        files = storage_client.list_blobs(\"fraud-detection-ml-models\",prefix=self.modelDirectory)\n",
    "        print(\" \")\n",
    "        print(\"Model Pickle files picked up for prediction\")\n",
    "        for picklefile in files:\n",
    "            for model_name in models_considered:\n",
    "                if model_name in picklefile.name:\n",
    "                   \n",
    "                    print(picklefile.name)\n",
    "                    try:\n",
    "                        blob = gcs.open(\"gs://fraud-detection-ml-models/\"+picklefile.name).read()\n",
    "                        model_pickle = self._pkl.loads(blob)\n",
    "                        self.pickled_models.append([model_pickle,model_name])\n",
    "                    except:\n",
    "                        print(\"Failed to load pkl file:\"+picklefile.name)\n",
    "                        \n",
    "                    \n",
    "                \n",
    "            \n",
    "        \n",
    "     \n",
    "    def process(self, element):\n",
    "        from apache_beam.io.gcp import gcsio\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        from google.cloud import storage\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        \n",
    "        import faiss\n",
    "        import numpy as np\n",
    "    \n",
    "        \n",
    "        print(\" \")\n",
    "        print(\"Payment Transaction: {} \".format(element))\n",
    "        \n",
    "        \n",
    "        #Data Transformation\n",
    "        new_x = self._pd.DataFrame.from_dict(element,orient = \"index\").transpose().fillna(0)\n",
    "        valid_type = ['CASH_OUT', 'PAYMENT', 'CASH_IN', 'TRANSFER', 'DEBIT']\n",
    "        encodertype = LabelEncoder()\n",
    "        encodertype.fit(valid_type)\n",
    "\n",
    "        encoderfunc = LabelEncoder()\n",
    "        \n",
    "        new_x['transaction_type'] = encodertype.transform(new_x['type'])\n",
    "        new_x['nameorig_enc'] = encoderfunc.fit_transform(new_x['nameOrig'])\n",
    "        new_x['namedest_enc'] = encoderfunc.fit_transform(new_x['nameDest'])\n",
    "        \n",
    "        new_x = new_x.drop(columns = ['type', 'nameOrig', 'nameDest', 'step'], axis =1)\n",
    "        new_x = new_x.rename(columns = {'oldbalanceOrg': 'oldbalanceOrig'})\n",
    "        \n",
    "        new_x['balance_difference'] = round(new_x['oldbalanceOrig'] - new_x['newbalanceOrig'], 2).ne(new_x['amount'])\n",
    "        new_x[\"balance_difference\"] = new_x[\"balance_difference\"].astype(int)\n",
    "        \n",
    "        print(\" \")\n",
    "        #print(\"Payment Data Post cleaning and Transformation: \")\n",
    "        #print(format(new_x))\n",
    "        \n",
    "        #Predictions for Each selected Model and Fold\n",
    "        \n",
    "        rf_predictions = []\n",
    "        svm_predictions = []\n",
    "        lof_predictions = []\n",
    "        knn_predictions = []\n",
    "        \n",
    "        for selected_model_data in self.pickled_models:\n",
    "            if(selected_model_data[1]=='rf'):\n",
    "                fraud_detect = selected_model_data[0].predict(new_x)[0]\n",
    "                rf_predictions.append(fraud_detect)\n",
    "            elif(selected_model_data[1]=='svm'):\n",
    "                fraud_detect = selected_model_data[0].predict(new_x)[0]\n",
    "                svm_predictions.append(fraud_detect)\n",
    "            elif(selected_model_data[1]=='knn'):\n",
    "                fraud_detect = selected_model_data[0].predict(np.ascontiguousarray(new_x))[0]\n",
    "                knn_predictions.append(fraud_detect)\n",
    "            elif(selected_model_data[1]=='lof'):\n",
    "                lof_detection = selected_model_data[0].decision_function(new_x)[0]\n",
    "                if(lof_detection>= 0):\n",
    "                    fraud_detect = 0 # Valid transactions are labelled as 0\n",
    "                else:\n",
    "                    fraud_detect = 1 # Fraudulent transactions are labelled as 1.\n",
    "                lof_predictions.append(fraud_detect)\n",
    "            \n",
    "        \n",
    "        #Ensemble individual models\n",
    "        rf_ensemble = max(set(rf_predictions),key=rf_predictions.count)\n",
    "        print(\"RF K-Fold Predictions: {}  : RF Ensemble: {} \".format(rf_predictions, rf_ensemble))\n",
    "        \n",
    "        svm_ensemble = max(set(svm_predictions),key=svm_predictions.count)\n",
    "        print(\"SVM K-Fold Predictions: {}  : SVM Ensemble: {} \".format(svm_predictions, svm_ensemble))\n",
    "        \n",
    "        knn_ensemble = max(set(knn_predictions),key=svm_predictions.count)\n",
    "        print(\"KNN K-Fold Predictions: {}  : KNN Ensemble: {} \".format(knn_predictions, knn_ensemble))\n",
    "        \n",
    "        all_model_predictions = [rf_ensemble,svm_ensemble,knn_ensemble]\n",
    "        final_ensemble_prediction = max(set(all_model_predictions),key=all_model_predictions.count)\n",
    "        print(\"All Model Predictions: {}  : Final Ensemble: {} \".format(all_model_predictions, final_ensemble_prediction))\n",
    "        \n",
    "        \n",
    "        #element['balance_change'] = round(new_x['oldbalanceOrig'] - new_x['newbalanceOrig'], 2)\n",
    "        element['fraud_prediction'] = final_ensemble_prediction #fraud_detect\n",
    "        element['model_used'] = self.winningmodel\n",
    "       \n",
    "        \n",
    "        return [ element ] \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2d30f-c652-44fe-b982-7610114c89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "detection = windowed_payments | \"Convert to dict\" >> beam.Map(json.loads) | 'Apply Model' >> beam.ParDo(ApplyDoFn()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48152d-8b37-42ac-a452-05d72d961d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib.show(detection, include_window_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4968b5-08cf-4125-b854-9d762f7699e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1edc70-da89-4a03-8130-d025df27c6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56014e84-5ef0-48f5-a5e2-97b4cbdd2864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d28d1-907e-42b5-953f-28adce4b4e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba044ad9-05ff-4c20-b44d-04c8deeddf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_events = (detection | \"json classified payments\" >> beam.Map(lambda x: json.dumps(x).encode(\"utf-8\"))) | \"classified payments to pubsub\" >> beam.io.WriteToPubSub(topic=\"projects/fraud-detection-data245/topics/payment_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90023b9e-31fb-4265-8b57-f94c04953c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6092d8-3ce5-47d7-83a9-1cc701af0b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1. Apache Beam 2.33.0 for Python 3",
   "language": "python",
   "name": "1-apache-beam-2.33.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
